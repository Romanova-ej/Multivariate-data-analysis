---
title: "Exploratory factor analysis"
author: "Romanova"
date: '11 ноября 2018 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=FALSE}
library(ade4)
library(dplyr)
library(ifa)
library(factoextra)
library(psych)
library(GPArotation)
library(corrplot)
```

```{r include=FALSE}
 na.mean <- function(vec) {
        m <- mean(vec, na.rm = TRUE)
        vec[is.na(vec)] <- m
        return(vec)
    }

```

```{r include=FALSE}
norm.off<-function(A,W){
  norm<-0
  for(i in 1:nrow(A)){
    for(j  in 1:ncol(A)){
      if(i !=j) norm=norm+A[i,j]^(2)/(W[i]*W[j])^2
    }
  }
  return(norm)
}
```

```{r include=FALSE}
fit.off.w<-function(FAw,corU,W){
 return(1-norm.off(residuals(FAw),W)/norm.off(corU,W))
}
```
Набор данных об американских университетах.
В составе даных 44 признака, харакеризующих с разных сторон уровень обучающихся в университете, его пристижность, преподавателей и т.д.
Также, как и в предыдущем случае (отчет по АГК), провели заранее агк для скоррелированных групп признаков и перешли к максимально информативным признакам.

```{r include=FALSE}
Univ<-read.table("I.txt",header=TRUE,sep=';')
Univ<-Univ[-c(26:28)]
for(i in 6:46){ 
  Univ[,i] <- as.numeric(gsub(",", ".", gsub("\\.", "", Univ[,i]))) 
}
Univ<-filter(Univ, X!="University of Califo")

Univ[,c(21:27,31:41)]<-log(Univ[,c(21:27,31:41)])

PPIND1<-filter(Univ, PPIND==1)
row.names(PPIND1)<-PPIND1$FICE
PPIND1<-PPIND1[6:46]

PPIND2<-filter(Univ,PPIND==2)
row.names(PPIND2)<-PPIND2$FICE
PPIND2<-PPIND2[6:46]

Un1<-apply(PPIND1, 2, na.mean)
Un1[,25]<-Un1[,25]^(-1)
Un1<-scale(Un1)

Un<-apply(Univ[,6:46],2,na.mean)
Un<-scale(Un)
```

```{r}
pca.quality<-dudi.pca(Un1[,c(1:10)],nf=1,scannf = FALSE)
new.Univ<-data.frame(-pca.quality$li) #качество студентов
colnames(new.Univ)<-c("quality") 
new.Univ$applicants<--dudi.pca(Un1[,11:13],nf=1,scannf = FALSE)$li #приток студентов, количественная характеристика
new.Univ$super.students<--dudi.pca(Un1[,14:15],nf=1,scannf = FALSE)$li # процент отличников 
new.Univ$num.students<-dudi.pca(Un1[,16:17],nf=1,scannf = FALSE)$li # количество студентов (количественная характеристика)
new.Univ$tuition<-dudi.pca(Un1[,18:19],nf=1,scannf = FALSE)$li # стоимость обучения
new.Univ$competence<-dudi.pca(Un1[,23:24],nf=1,scannf = FALSE)$li # компетентность преподавателей 
new.Univ$fs.ratio<-Un1[,25] # отношение числа преподавателей к числу студентов (чем больше, тем лучше)
new.Univ$donate<-Un1[,26] # процент успешных выпускников
new.Univ$instruct<-Un1[,27] # средства, выделяемые на одного ученика 
new.Univ$graduate<-Un1[,28] # процент выпустившихся судентов
new.Univ$salary<--dudi.pca(Un1[,29:36],nf=1,scannf = FALSE)$li # заработок преподавателей 
new.Univ$num.teachers<--dudi.pca(Un1[,37:41],nf=1,scannf = FALSE)$li # количество преподавателей (количественная характеристика)
new.Univ<-as.matrix(new.Univ)
Univ1.active<-as.data.frame(new.Univ)
```

 Сначала, чтобы не зайти слишком далеко, установим, есть ли в данных вообще какая-то структура, при помощи критерия Бартлетта. Этот критерий проверяет гипотезу о том, что $\Sigma=\mathbf{I}$.
```{r warning=FALSE}
cor.Univ<-cor(Univ1.active)
cortest.bartlett(cor.Univ,n=115)
```
Гипотеза отвергается, следовательно, есть смысл продолжать. (На самом деле это говорит только о том, что некоторые наши переменные связаны друг с другом и всё).

Иногда для проверки наличия в данных каких-то скрытых признаков используют меру адекватности выборки  Kaiser-Meyer-Olkin. Тест KMO проверяет, достаточно ли близки к нулю частные корреляции в ваших данных, чтобы предположить, что есть хотя бы один скрытый фактор, лежащий в основе ваших переменных. Минимально допустимое значение составляет 0,50, но большинство авторов рекомендуют значение 0,60 перед проведением факторного анализа.
```{r warning=FALSE}
KMO(Univ1.active)
```

Значение 0.73 -- сойдет.

Теперь нужно подобрать модель, решить, сколько факторов мы будем извлекать. Для этого могут использоваться различные методы (здесь рассматриваем scree plot and parallel analysis)
```{r warning=FALSE}
fa.parallel(Univ1.active,n.iter = 100,main = "Диаграммы собственных значений с параллельным анализом",fa="both",fm="mle")
```

Нам советуют брать 4 фактора. 
Первые 4 собственных значений (треугольники) превышают среднее значение 
собственных значений, полученных на основании 100 смоделированных матриц данных (для белого шума). 
По критерию scree plot как таковому тоже +- видно, что "камни начинают сыпаться" после 4го фактора.

Проведем факторный анализ без вращений.
```{r warning=FALSE}
efa.res<-fa( Univ1.active, nfactors=4, fm="mle",rotate = "none")
```

Пробуем интерпретировать полученные факоры.
```{r warning=FALSE}
print(efa.res$loadings,cutoff=0.3, sort = TRUE)
```

Первый фактор влияет почти на все переменные. Мы бы хотели больше нулей. Вращаем. Сначала попробуем ортогонально.
```{r warning=FALSE}
efa.res<-fa( Univ1.active, nfactors=4, fm="mle",rotate = "varimax",scores = "Bartlett")
print(efa.res$loadings,cutoff=0.3,sort = TRUE)
```

Вращаем косоугольно:
```{r warning=FALSE}
efa.res<-fa( Univ1.active, nfactors=4, fm="mle",rotate = "oblimin")
print(efa.res$loadings,cutoff=0.3,digits = 2,sort = TRUE)
```

Марица стала значительно "чище".
Остановимся на косоугольных вращениях. 

Итак, пусть будет 
```{r warning=FALSE}
efa.res<-fa( Univ1.active, nfactors=4, fm="mle",rotate = "oblimin")
efa.res
```

Интерпретировать фактороры удобно при помощи следующей диаграммы (при базовых настройках функции здесь все совсем красивенько, но нам нужны эти пересекающиеся стрелочки):
```{r warning=FALSE}
fa.diagram(efa.res,cut = 0.25,simple = FALSE)
```

Второй фактор, влияющий на взаимосвязи исходных признаков, -- размер университета.
Первый факор -- качество преподавательского состава. 
Третий фактор -- качество самих студентов.
Четвертый фактор -- престижность университета.

Так как мы использовали косоугольные вращения, нужно посмотреть и на матрицу factor structure корреляций между исходными признаками и извлеченными факторами.
```{r}
print(efa.res$Structure, cutoff=0.3, digits=3)
```

Эти результаты, в принципе, не противоречат интерпретации факторов, приведенной выше. 
Но интерпретировать факторы только на основе factor structure сложно, так как много больших по модулю значений (в отличие от factor pattern, который мы максимально упростили при помощи вращений).


Биплот (для вычисления факторных значений используется метод Бартлетта):
```{r warning=FALSE}
biplot(efa.res$scores[], loadings(efa.res))
```


Общность (communality) для каждой переменной -- это процент дисперсии, который объясняется извлекаемыми факторами. (Конечно, хорошо, если факторы объясняют как можно больше дисперсии в каждой переменной.)
```{r warning=FALSE}
efa.res$communality
```

Факторный анализ не объясняет уникальности признаков:
```{r}
efa.res$uniquenesses
```
Процент успешных студентов (donate) обладает сильной уникальностью. Также не слишком хорошо объясняются переменные tuition, competence, salary.

###Остаточные корреляции

Воспроизведенные и остаточные корреляции. Дополнительным способом проверки числа выделенных факторов является вычисление корреляционной матрицы, которая близка исходной, если факторы выделены правильно. Эта матрица называется воспроизведенной корреляционной матрицей. Для того чтобы увидеть, как эта матрица отклоняется от исходной корреляционной матрицы (с которой начинался анализ), можно вычислить разность между ними. Полученная матрица называется матрицей остаточных корреляций. Остаточная матрица может указать на "несогласие", т.е. на то, что рассматриваемые коэффициенты корреляции не могут быть получены с достаточной точностью на основе имеющихся факторов.

Матрица остаточных корреляций для нашей модели:
```{r warning=FALSE}
residuals(efa.res)
efa.res$fit
efa.res$fit.off
```

Есть критерии, которые изначально помогают выбрать количество факторов на основе того, насколько хорошо модель приближает корреляционную матрицу. Критерий VSS - Very Simple Structure Criterion. Статистика VSS:
$$
VSS
=
\frac{\sum s_{ij}^{2}-\sum {s_{ij}^{\ast}}^{2}}{\sum s_{ij}^{2}},
$$

где $\mathbb{S}=(s_{ij})$ --- выборочная корреляционная матрица, $S^{\ast}=(s_{ij}^{\ast})=\mathbb{S}-\hat{\mathbb{F}_{r}^{\prime}}\hat{\mathbb{F}_{r}^{\prime}}^{\mathrm{T}}$ --- матрица остатков. То есть 1-относительная ошибка. Таким образом, чем значение больше, тем лучше.
Отметим, что в $\hat{\mathbb{F}_{r}^{\prime}}$ не есть $\hat{\mathbb{F}_{r}}$. Тут входят не все веса, а только $c$ наибольших (по модулю) для каждой переменной. (тут реализована тенденция людей смотреть только на несколько самых больших коэффициентов и интерпретировать только их). То есть тут используется упрощенная матрица факторных весов. с (complexity) изменяется от 1 до количества факторов.

```{r warning=FALSE}
VSS(Univ1.active,n=7,rotate = "varimax",fm="mle" )
```

Модель с 4мя факторами лучше всех, ура! Значит, можем не удалять с позором все то, что сделали выше (впрочем, мы в начале использовали другие методы для определения числа факторов, они также имеют полное право на существование, возможно, даже большее, чем этот "критерий").

###Метод-остаточные корреляции

Метод minres основан на минимизации остаточных корреляций в матричной норме Фробениуса (по недиагональным элементам). Взвешенный вариант минимизирует взвешенную сумму квадратов. Решение по методу максимального правдопобобия схоже с решением по wls. 

Рассмотрим результаты факторного анализа с использованием 3х методов нахождения факторных весов (без вращений):
```{r warning=FALSE}
wls <- fa(Univ1.active, nfactors=4,rotate="none",fm="wls")
minres <-  fa(Univ1.active, nfactors=4,rotate="none",fm="minres")
mle <- fa(Univ1.active, nfactors=4,rotate="none",fm="mle")
```

Значение fit.off, хранящееся в объекте типа fa(), показывает, насколько хорошо матрица в модели приближает исходную корреляционную матрицу. 
$$
\mathrm{fit.off}=
1-
\frac{\sum_{i\neq j}r_{ij}^{2}}{\sum_{i\neq j}s_{ij}^{2}},
$$

где $R=(r_{ij})$ -- матрица остаточных корреляций, а $S=(s_{ij})$ -- выборочная корреляционная матрица.

Очевидно, что норма Фробениуса (по недиагональным элементам) будет минимальна в методе minres (по построению метода), то есть значение переменной fit.off наоборот будет максимально:
```{r}
minres$fit.off
wls$fit.off
mle$fit.off
```

Также понятно, что если измерять ошибку в другой норме, результат может быть другим. 

